# -*- coding: utf-8 -*-
"""5_19101069_Md Mahbubur Rahman.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rmq2MaSJscmDyunkSSS8C09aE_cP7Sn9
"""

import numpy as np
import pandas as pd

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA

import matplotlib.pyplot as plt

volunteer = pd.read_csv('/content/leaf_dataset.csv')
volunteer.head(6)

volunteer.isnull().sum()

volunteer[['Elongation', 'Maximal Indentation Depth', 'Lobedness', 'Average Contrast', 'Entropy']]

impute = SimpleImputer(missing_values = np.nan, strategy = 'mean')

impute.fit(volunteer[['Elongation']])
volunteer['Elongation'] = impute.transform(volunteer[['Elongation']])


impute.fit(volunteer[['Maximal Indentation Depth']])
volunteer['Maximal Indentation Depth'] = impute.transform(volunteer[['Maximal Indentation Depth']])


impute.fit(volunteer[['Lobedness']])
volunteer['Lobedness'] = impute.transform(volunteer[['Lobedness']])


impute.fit(volunteer[['Average Contrast']])
volunteer['Average Contrast'] = impute.transform(volunteer[['Average Contrast']])

volunteer.isnull().sum()

volunteer['Class(species)'].unique()

label = volunteer['Class(species)']
feature = volunteer.drop('Class(species)', axis=1)

x_train, x_test, y_train, y_test = train_test_split(feature, label, test_size = 0.2, random_state = 1)

scalar = MinMaxScaler()
scalar.fit(x_train)
x_train_scaled = scalar.transform(x_train)

scalar.fit(x_test)
x_test_scaled = scalar.transform(x_test)

#SVC

svc = SVC(kernel = "linear")
svc.fit(x_train_scaled, y_train)
SVC_acc = svc.score(x_test_scaled, y_test)*100
SVC_acc

#NN

nn = MLPClassifier(activation = "relu", hidden_layer_sizes = (7), max_iter = 10000)
nn.fit(x_train_scaled, y_train)
NN_acc = nn.score(x_test_scaled, y_test)*100
NN_acc

#RF

rfc = RandomForestClassifier(n_estimators=50)
rfc.fit(x_train_scaled, y_train)
RF_acc = rfc.score(x_test_scaled, y_test)*100
RF_acc

#PCA

pca = PCA(n_components = 7)

pca.fit(x_train_scaled)
x_train_scaled_pca = pca.transform(x_train_scaled)
x_test_scaled_pca = pca.transform(x_test_scaled)

#PCA SVC

from sklearn.svm import SVC
svc = SVC(kernel = "linear")
svc.fit(x_train_scaled_pca, y_train)
SVC_acc_PCA = svc.score(x_test_scaled_pca, y_test)*100
SVC_acc_PCA

#PCA NN

from sklearn.neural_network import MLPClassifier
nn = MLPClassifier(activation = "relu", hidden_layer_sizes = (7), max_iter = 10000)
nn.fit(x_train_scaled_pca, y_train)
NN_acc_PCA = nn.score(x_test_scaled_pca, y_test)*100
NN_acc_PCA

#PCA RF

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators = 50)
rfc.fit(x_train_scaled_pca, y_train)

RFC_acc_PCA = rfc.score(x_test_scaled_pca, y_test)*100
RFC_acc_PCA

#Non-PCA v/ PCA
plt.figure(figsize = (20, 20))
xAxis = ['SVC', 'PCA SVC', 'Neural Network', 'PCA Neural Network', 'Random Forest', 'PCA Random Forest']
yAxis = [SVC_acc, SVC_acc_PCA, NN_acc, NN_acc_PCA, RF_acc, RFC_acc_PCA]
plt.bar(xAxis, yAxis, color="r")
plt.show()